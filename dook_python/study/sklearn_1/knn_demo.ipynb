{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(\u0027\\xe9\\x82\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xef\\xbc\\x9a\u0027, array([[2, 1],\n       [1, 2],\n       [3, 4],\n       [5, 4],\n       [4, 5],\n       [0, 1]]))\n(\u0027\\xe9\\x82\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe8\\xb7\\x9d\\xe7\\xa6\\xbb\\xef\\xbc\\x9a\u0027, array([[0.2236068 , 1.62788206],\n       [0.67082039, 0.80622577],\n       [0.4       , 0.6       ],\n       [0.60827625, 1.94164878],\n       [0.5       , 1.11803399],\n       [0.36055513, 0.85440037]]))\n(\u0027\\xe9\\x82\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xef\\xbc\\x9a\u0027, array([[0, 1],\n       [1, 0],\n       [2, 1],\n       [3, 4],\n       [4, 3],\n       [5, 4]]))\n(\u0027\\xe9\\x82\\xbb\\xe8\\x8a\\x82\\xe7\\x82\\xb9\\xe8\\xb7\\x9d\\xe7\\xa6\\xbb\\xef\\xbc\\x9a\u0027, array([[0.        , 1.        ],\n       [0.        , 1.        ],\n       [0.        , 1.41421356],\n       [0.        , 1.        ],\n       [0.        , 1.        ],\n       [0.        , 1.41421356]]))\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# -*- coding: UTF-8 -*-\n# \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d无监督查找最近邻（常在聚类中使用，例如变色龙聚类算法）\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n\nfrom sklearn.neighbors import NearestNeighbors\nimport numpy as np # 快速操作结构数组的工具\n\nX \u003d np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])  # 样本数据\ntest_x \u003d np.array([[-3.2, -2.1], [-2.6, -1.3], [1.4, 1.0], [3.1, 2.6], [2.5, 1.0], [-1.2, -1.3]])  # 设置测试数据\n# test_x\u003dX  # 测试数据等于样本数据。这样就相当于在样本数据内部查找每个样本的邻节点了。\nnbrs \u003d NearestNeighbors(n_neighbors\u003d2, algorithm\u003d\u0027ball_tree\u0027).fit(X)  # 为X生成knn模型\ndistances, indices \u003d nbrs.kneighbors(test_x)  # 为test_x中的数据寻找模型中的邻节点\nprint(\u0027邻节点：\u0027,indices)\nprint(\u0027邻节点距离：\u0027,distances)\n\n# \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d使用kd树和Ball树实现无监督查找最近邻\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n\nfrom sklearn.neighbors import KDTree,BallTree\nimport numpy as np # 快速操作结构数组的工具\n\nX \u003d np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n# test_x \u003d np.array([[-3.2, -2.1], [-2.6, -1.3], [1.4, 1.0], [3.1, 2.6], [2.5, 1.0], [-1.2, -1.3]])  # 设置测试数据\ntest_x\u003dX  # 测试数据等于样本数据。这样就相当于在样本数据内部查找每个样本的邻节点了。\nkdt \u003d KDTree(X, leaf_size\u003d30, metric\u003d\u0027euclidean\u0027)\ndistances,indices \u003d kdt.query(test_x, k\u003d2, return_distance\u003dTrue)\nprint(\u0027邻节点：\u0027,indices)\nprint(\u0027邻节点距离：\u0027,distances)\n"
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python2",
      "language": "python",
      "display_name": "Python 2"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "# -*- coding: UTF-8 -*-",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}